{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imghdr\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/giacomorossi/Desktop/progetti/Neural Network/Happy/foto'\n",
    "images_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
    "\n",
    "#preprocess of images on the fly\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path)\n",
    "            tip = imghdr.what(image_path)\n",
    "            if tip not in images_exts:\n",
    "                print('image not in ext list {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print('Issue with image {}'.format(image_path))\n",
    "            #os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates batches\n",
    "#class 1 -> sad\n",
    "#class 0 -> happy\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 8, figsize = (20, 20))\n",
    "for idx, img in enumerate(batch[0][:8]):\n",
    "  ax[idx].imshow(img.astype(int))\n",
    "  ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_s = data.map(lambda x, y: (x/255, y))\n",
    "scaled_iterator = data_s.as_numpy_iterator()\n",
    "batch = scaled_iterator.next()\n",
    "\n",
    "fig, ax = plt.subplots(ncols = 4, figsize = (20, 20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "  ax[idx].imshow(img)\n",
    "  ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_s)*32 #batch size\n",
    "\n",
    "train_size = int(len(data_s)*.7)\n",
    "val_size = int(len(data_s)*.15)\n",
    "test_size = int(len(data_s)*.15)\n",
    "train = data_s.take(train_size)\n",
    "val = data_s.skip(val_size)\n",
    "test = data_s.skip(train_size*val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input layer corresponding to the shape of the images\n",
    "#it has 16 filters to scan the images with the filter size of (3, 3) px.\n",
    "#it as a stride of 1, it moves 1px per time\n",
    "model.add(Conv2D(16, (3, 3), 1, activation = 'relu', input_shape = (256, 256, 3)))\n",
    "model.add(MaxPooling2D()) #reduces the images looking at the max value of the size taken (2x2 by default -> halfs the images)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), 1, activation = 'relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten()) #brings all in one channel\n",
    "\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid')) #output layer\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = tf.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
    "hist = model.fit(train, epochs = 20, validation_data = val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('HappyImageClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/Users/giacomorossi/Desktop/progetti/Neural Network/Happy/HappyImageClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('INSERT IMAGE')\n",
    "resize = tf.image.resize(img, (256, 256))\n",
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "if yhat.round() == 1:\n",
    "  print('sad person')\n",
    "else: \n",
    "  print('happy person')\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0050e35b96a85cac2a2d60634db1914fea21e262b31a3e13b1c42ead2b9609b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
